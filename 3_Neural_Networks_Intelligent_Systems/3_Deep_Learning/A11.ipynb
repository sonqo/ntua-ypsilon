{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sonqo/Ntua_Ypsilon/blob/master/3_Neural_Networks_Intelligent_Systems/3_Deep_Learning/A11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2IcJXcTy-Qs",
        "colab_type": "text"
      },
      "source": [
        "# Εισαγωγή\n",
        "Στα εργαστήρια φέτος δουλέψαμε με τη βιβλιοθήκη TensorFlow 1 και το σύνολο δεδομένων CIFAR-10.\n",
        "\n",
        "Ο βασικός στόχος της παρούσας άσκησης είναι η εξοικείωση με τη βιβλιοθήκη **TensorFlow 2**. Κάθε ομάδα θα δουλέψει σε ένα διαφορετικό υποσύνολο του συνόλου δεδομένων **CIFAR-100**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpieffc31YMY",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow 2 (vs TensorFlow 1)\n",
        "\n",
        "![alt text](https://miro.medium.com/max/4928/1*-QTg-_71YF0SVshMEaKZ_g.png)\n",
        "Η βιβλιοθήκη TensorFlow 2 διαδέχθηκε την TensorFlow 1 τον Οκτώβριο του 2019 και η τελευταία έκδοσή της αυτή τη στιγμή είναι η 2.1.0 (8 Ιανουαρίου 2020). \n",
        "\n",
        "Οι δύο πιο σημαντικές διαφορές του TensorFlow 2 σε σχέση με το TensorFlow 1 είναι οι εξής:\n",
        "\n",
        "1. **Απλοποίηση της χρήσης - Keras API**: το tf2 χρησιμοποιεί πλέον ως high-level API το tf.keras, δηλαδή τη δική του υλοποίηση της προδιαγραφής API του Keras. Επίσης διάφορα δομοστοιχεία του tf1 αφαιρέθηκαν, συγχωνεύθηκαν ή μετακινήθηκαν σε υποπακέτα ώστε να “καθαρίσει” o ονοματοχώρος tf.*.\n",
        "\n",
        "2. **Πρόθυμη εκτέλεση (Eager execution)**: στο tf1 το γράψιμο του κώδικα χωρίζεται σε δύο μέρη, στον ορισμό του υπολογιστικού γράφου και στη συνέχεια στον ορισμό μιας συνεδρίας (session) για την εκτέλεσή του. Tο tf2, όπως συνήθως και η Python, εκτελεί πρόθυμα τον κώδικα και δεν χρειάζεται ξεχωριστός ορισμός συνεδριών: ο γράφος και η συνεδρία αποτελούν στοιχεία μιας ενιαίας υλοποίησης.\n",
        "\n",
        "Μεταξύ των υπόλοιπων νέων χαρακτηριστικών και διαφορών του tf2 σε σχέση με το tf1 που μπορούμε να ξεχωρίσουμε είναι: \n",
        "- η **απλοποίηση της διοχέτευσης (pipeline)** των δεδομένων. Με το tf.data του tf2 μπορούμε να έχουμε απευθείας πρόσβαση σε σύνολα δεδομένων αλλά και να εκτελούμε μετασχηματισμούς με απλό τρόπο. Επίσης, σε αντίθεση με το tf1, δεν απαιτείται καθόλου η δήλωση συμβόλων αντικατάστασης (placeholders) στον ορισμό του γράφου τα οποία στη συνέχεια θα χρησιμοποιηθούν για την εισαγωγή των δεδομένων στο δίκτυο.\n",
        "- η **απαλοιφή καθολικών μεταβλητών**. Το tf1 βασίζονταν σε μεγάλο βαθμό σε καθολικές μεταβλητές οι οποίες ήταν προσπελάσιμες μόνο από το όνομά τους, το οποίο όμως δεν είναι πάντα γνωστό εφόσον πολύ συχνά έχει οριστεί από άλλους. Σο tf2 ο χρήστης καλείται να παρακολουθεί τις μη καθολικές μεταβλητές του ο ίδιος με τη βοήθεια αντικειμένων του Keras, χωρίς να χρειάζεται πλέον η καθολική υποδομή γύρω από τις μεταβλητές.\n",
        "- η **εγκαθίδρυση του SavedModel** format (of TensorFlow 2) ως ενιαίο τρόπο αποθήκευσης, φόρτωσης και ανταλλαγής μοντέλων στα TensorFlow, TensorFlow Serving, TensorFlow Lite, TensorFlow.js, TensorFlow Hub κλπ.\n",
        "\n",
        "Περισσότερα: [Effective TensorFlow 2](https://www.tensorflow.org/guide/effective_tf2), [Overview of changes TensorFlow 1.0 vs TensorFlow 2.0](https://www.datasciencecentral.com/profiles/blogs/tensorflow-1-x-vs-2-x-summary-of-changes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUPTXpNqvrB0",
        "colab_type": "text"
      },
      "source": [
        "# Σύνολο δεδομένων CIFAR-100\n",
        "![alt text](https://datarepository.wolframcloud.com/resources/images/69f/69f1e629-81e6-4eaa-998f-f6734fcd2cb3-io-4-o.en.gif)\n",
        "\n",
        "To [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) όπως και το CIFAR-10 που είδαμε στο εργαστήριο είναι επισημειωμένα υποσύνολα του συνόλου δεδομένων “80 million tiny images”. Τα συνέλλεξαν οι Alex Krizhevsky (πρώτος συγγραφέας του [AlexNet - 2012](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)), Vinod Nair (πρώτος συγγραφέας των [ReLU - 2010](https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf)) και ο Geoffrey Hinton.\n",
        "\n",
        "Το CIFAR-100 αποτελείται από **60000 έγχρωμες εικόνες των 32x32 pixel χωρισμένες σε 100 κατηγορίες**. Σε κάθε κατηγορία αντιστοιχούν 500 εικόνες εκπαίδευσης και 100 εικόνες ελέγχου, δηλαδή το train-test split είναι προκαθορισμένο. **Κάθε μια από τις 100 κατηγορίες του CIFAR-100 ανήκει και σε μια από 20 υπερκατηγορίες**, για παράδειγμα οι κατηγορίες “maple”, “oak”, “palm”, “pine” και “willow” ανήκουν στην υπερκατηγορία “trees”. Κάθε εικόνα έχει δύο ετικέτες, μια “fine” που δείχνει την κατηγορία της και μια “coarse” που δείχνει την υπερκατηγορία της. **Θα δουλέψουμε αποκλειστικά με τις κατηγορίες (\"fine\")**.\n",
        "\n",
        "**To CIFAR-100 είναι, όπως είναι αναμενόμενο, σημαντικά πιο δύσκολο dataset από το CIFAR-10.** Μέχρι το 2019, η απόδοση των συστημάτων state-of-the-art στο CIFAR-10 ήταν ορθότητα (accuracy) [99.00%](https://benchmarks.ai/cifar-10https://) (GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism) ενώ στο CIFAR-100 ήταν [91.70%](https://benchmarks.ai/cifar-100https://)\n",
        "(EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks)\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsRt5JelvV7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo pip install --upgrade pip\n",
        "!sudo pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpnEVMCYYlnD",
        "colab_type": "text"
      },
      "source": [
        "# Έαν απλό παράδειγμα υλοποίησης"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfEMjsB4Yurm",
        "colab_type": "text"
      },
      "source": [
        "## Εισαγωγή και επισκόπηση του συνόλου δεδομένων"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STXQMBuN3nZ6",
        "colab_type": "code",
        "outputId": "379e3dc7-8bde-4be3-c2dc-8f9d465a7ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals # legacy compatibility\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WSEGPI9Q7tW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper functions\n",
        "\n",
        "# select from from_list elements with index in index_list\n",
        "def select_from_list(from_list, index_list):\n",
        "  filtered_list= [from_list[i] for i in index_list]\n",
        "  return(filtered_list)\n",
        "\n",
        "# append in filtered_list the index of each element of unfilterd_list if it exists in in target_list\n",
        "def get_ds_index(unfiliterd_list, target_list):\n",
        "  index = 0\n",
        "  filtered_list=[]\n",
        "  for i_ in unfiliterd_list:\n",
        "    if i_[0] in target_list:\n",
        "      filtered_list.append(index)\n",
        "    index += 1\n",
        "  return(filtered_list)\n",
        "\n",
        "# select a url for a unique subset of CIFAR-100 with 20, 40, 60, or 80 classes\n",
        "def select_classes_number(classes_number = 20):\n",
        "  cifar100_20_classes_url = \"https://pastebin.com/raw/nzE1n98V\"\n",
        "  cifar100_40_classes_url = \"https://pastebin.com/raw/zGX4mCNP\"\n",
        "  cifar100_60_classes_url = \"https://pastebin.com/raw/nsDTd3Qn\"\n",
        "  cifar100_80_classes_url = \"https://pastebin.com/raw/SNbXz700\"\n",
        "  if classes_number == 20:\n",
        "    return cifar100_20_classes_url\n",
        "  elif classes_number == 40:\n",
        "    return cifar100_40_classes_url\n",
        "  elif classes_number == 60:\n",
        "    return cifar100_60_classes_url\n",
        "  elif classes_number == 80:\n",
        "    return cifar100_80_classes_url\n",
        "  else:\n",
        "    return -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCW71UaGzz0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the entire dataset\n",
        "(x_train_all, y_train_all), (x_test_all, y_test_all) = tf.keras.datasets.cifar100.load_data(label_mode='fine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PO9wIwYUf0R",
        "colab_type": "text"
      },
      "source": [
        "Η κάθε ομάδα θα δουλέψει με \n",
        "Στο επόμενο κελί, αντικαταστήστε την τιμή της μεταβλητής `team_seed` με τον αριθμό που αντιστοιχεί στην ομάδας σας σε [αυτό το σύνδεσμο](https://docs.google.com/spreadsheets/d/1oEr3yuPg22lmMeqDjFtWjJRzmGQ8N57YIuV-ZOvy3dM/edit?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN0kEze7uZ_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# REPLACE WITH YOUR TEAM NUMBER\n",
        "team_seed = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xYQ_Q1SVZEk",
        "colab_type": "text"
      },
      "source": [
        "Στο επόμενο κελί μπορείτε να διαλέξετε το πλήθος των κατηγορίων σας: 20 (default), 40, 60 ή 80."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhbZJW6PxUDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select the number of classes\n",
        "cifar100_classes_url = select_classes_number()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO9f6wb0Wi0H",
        "colab_type": "text"
      },
      "source": [
        "Δημιουργούμε το μοναδικό dataset της ομάδας μας:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgIN2h_KuCp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "team_classes = pd.read_csv(cifar100_classes_url, sep=',', header=None)\n",
        "CIFAR100_LABELS_LIST = pd.read_csv('https://pastebin.com/raw/qgDaNggt', sep=',', header=None).astype(str).values.tolist()[0]\n",
        "\n",
        "our_index = team_classes.iloc[team_seed,:].values.tolist()\n",
        "our_classes = select_from_list(CIFAR100_LABELS_LIST, our_index)\n",
        "train_index = get_ds_index(y_train_all, our_index)\n",
        "test_index = get_ds_index(y_test_all, our_index)\n",
        "\n",
        "x_train_ds = np.asarray(select_from_list(x_train_all, train_index))\n",
        "y_train_ds = np.asarray(select_from_list(y_train_all, train_index))\n",
        "x_test_ds = np.asarray(select_from_list(x_test_all, test_index))\n",
        "y_test_ds = np.asarray(select_from_list(y_test_all, test_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B4-tvVOQq3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print our classes\n",
        "print(our_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpGXgTs_5ZCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get (train) dataset dimensions\n",
        "data_size, img_rows, img_cols, img_channels = x_train_ds.shape\n",
        "\n",
        "# set validation set percentage (wrt the training set size)\n",
        "validation_percentage = 0.15\n",
        "val_size = round(validation_percentage * data_size)\n",
        "\n",
        "# Reserve val_size samples for validation and normalize all values\n",
        "x_val = x_train_ds[-val_size:]/255\n",
        "y_val = y_train_ds[-val_size:]\n",
        "x_train = x_train_ds[:-val_size]/255\n",
        "y_train = y_train_ds[:-val_size]\n",
        "x_test = x_test_ds/255\n",
        "y_test = y_test_ds\n",
        "\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "print('Validation: X=%s, y=%s' % (x_val.shape, y_val.shape))\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
        "\n",
        "# get class label from class index\n",
        "def class_label_from_index(fine_category):\n",
        "  return(CIFAR100_LABELS_LIST[fine_category.item(0)])\n",
        "\n",
        "# plot first few images\n",
        "plt.figure(figsize=(6, 6))\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "  plt.subplot(330 + 1 + i).set_title(class_label_from_index(y_train[i]))\n",
        "\t# plot raw pixel data\n",
        "  plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
        "  #show the figure\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cniJE8eZQAA",
        "colab_type": "text"
      },
      "source": [
        "## Συναρτήσεις εκπαίδευσης"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3xB9x5JZjSN",
        "colab_type": "text"
      },
      "source": [
        "Θα χρησιμοποιήσουμε την ιδιότητα data prefetch του tf2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPFYqOmIa5Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we user prefetch https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch \n",
        "# see also AUTOTUNE\n",
        "# the dataset is now \"infinite\"\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE # https://www.tensorflow.org/guide/data_performance\n",
        "\n",
        "def _input_fn(x,y, BATCH_SIZE):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "  ds = ds.shuffle(buffer_size=data_size)\n",
        "  ds = ds.repeat()\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds =_input_fn(x_train,y_train, BATCH_SIZE) #PrefetchDataset object\n",
        "validation_ds =_input_fn(x_val,y_val, BATCH_SIZE) #PrefetchDataset object\n",
        "test_ds =_input_fn(x_test,y_test, BATCH_SIZE) #PrefetchDataset object\n",
        "\n",
        "# steps_per_epoch and validation_steps for training and validation: https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "\n",
        "def train_model(model, epochs = 10, steps_per_epoch = 2, validation_steps = 1):\n",
        "  history = model.fit(train_ds, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_data=validation_ds, validation_steps=validation_steps)\n",
        "  return(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onYIggE9Z2f4",
        "colab_type": "text"
      },
      "source": [
        "## Γραφικές παραστάσεις εκπαίδευσης και απόδοση στο σύνολο ελέγχου"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdWPm3zqbRo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\tplt.figure(figsize=(8, 8))\n",
        "\tplt.suptitle('Training Curves')\n",
        "\t# plot loss\n",
        "\tplt.subplot(211)\n",
        "\tplt.title('Cross Entropy Loss')\n",
        "\tplt.plot(history.history['loss'], color='blue', label='train')\n",
        "\tplt.plot(history.history['val_loss'], color='orange', label='val')\n",
        "\tplt.legend(loc='upper right')\n",
        "\t# plot accuracy\n",
        "\tplt.subplot(212)\n",
        "\tplt.title('Classification Accuracy')\n",
        "\tplt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tplt.plot(history.history['val_accuracy'], color='orange', label='val')\n",
        "\tplt.legend(loc='lower right')\n",
        "\treturn plt\n",
        " \n",
        "# print test set evaluation metrics\n",
        "def model_evaluation(model, evaluation_steps):\n",
        "\tprint('\\nTest set evaluation metrics')\n",
        "\tloss0,accuracy0 = model.evaluate(test_ds, steps = evaluation_steps)\n",
        "\tprint(\"loss: {:.2f}\".format(loss0))\n",
        "\tprint(\"accuracy: {:.2f}\".format(accuracy0))\n",
        "\n",
        "def model_report(model, history, evaluation_steps = 10):\n",
        "\tplt = summarize_diagnostics(history)\n",
        "\tplt.show()\n",
        "\tmodel_evaluation(model, evaluation_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Waa4c40Yay3k",
        "colab_type": "text"
      },
      "source": [
        "## Μοντέλα δικτύων"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFTzQtMOa3Rv",
        "colab_type": "text"
      },
      "source": [
        "### Ένα μικρό συνελικτικό δίκτυο \"from scratch\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtcgTkHojt0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a simple CNN https://www.tensorflow.org/tutorials/images/cnn\n",
        "\n",
        "def init_simple_model(summary):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(100, activation='softmax'))\n",
        "  model.compile(optimizer=tf.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])\n",
        "  if summary: \n",
        "    model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSbtouO9lGvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SIMPLE_MODEL = init_simple_model(summary = True)\n",
        "SIMPLE_MODEL_history = train_model(SIMPLE_MODEL, 50, 30, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmyw-txxnzrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_report(SIMPLE_MODEL, SIMPLE_MODEL_history, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12z4zsoVbPWR",
        "colab_type": "text"
      },
      "source": [
        "### Μεταφορά μάθησης: VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QJueWvUXUTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transfer learning: VGG16 trained on ImageNet without the top layer\n",
        "\n",
        "def init_VGG16_model(summary):\n",
        "  VGG16_MODEL=tf.keras.applications.VGG16(input_shape=(img_rows, img_cols, img_channels), include_top=False, weights='imagenet')\n",
        "\n",
        "  # unfreeze conv layers\n",
        "  VGG16_MODEL.trainable=True\n",
        "\n",
        "  dropout_layer = tf.keras.layers.Dropout(rate = 0.5)\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "  # add top layer for CIFAR100 classification\n",
        "  prediction_layer = tf.keras.layers.Dense(len(CIFAR100_LABELS_LIST),activation='softmax')\n",
        "  model = tf.keras.Sequential([VGG16_MODEL, dropout_layer, global_average_layer, prediction_layer])\n",
        "  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.00005), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])\n",
        "  if summary: \n",
        "    model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR-bPAmGGt2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VGG16_MODEL = init_VGG16_model(summary = True)\n",
        "VGG16_MODEL_history = train_model(VGG16_MODEL, 25, 40, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bZChKpdh0Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_report(VGG16_MODEL, VGG16_MODEL_history, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUfob-kNfaSD",
        "colab_type": "text"
      },
      "source": [
        "# Βελτίωση της επίδοσης με πειράματα\n",
        "\n",
        "Καλείστε να βελτιώσετε τα αποτελέσματα ταξινόμησης στο CIFAR-100 και να βγάλατε συμπεράσματα, σύμφωνα με όσα ζητούνται σε σχέση με την αναφορά παράδοσης. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiVKTH5rmhWn",
        "colab_type": "text"
      },
      "source": [
        "## Δοκιμές διαφορετικών μοντέλων\n",
        "\n",
        "Μπορείτε είτε να δοκιμάσετε μοντέλα \"from scratch\", όπου ορίζετε την αρχιτεκτονική του δικτύου όπως θέλετε, είτε να χρησιμοποιήσετε μεταφορά μάθησης.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAbqI8hapbX9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Μοντέλα \"from scratch\"\n",
        "\n",
        "Μπορείτε να τροποποιήσετε/αλλάξετε το αρχικό μικρό συνελικτικό δίκτυο του παραδείγματος. Μπορείτε να συμβουλευτείτε \n",
        "- τη [βιβλιογραφία απο το leaderboard του CIFAR-100](https://benchmarks.ai/cifar-100) για αρχιτεκτονικές και παραμέτρους των δικτύων\n",
        "- ή/και να πάρετε ιδέες [από σχετική αναζήτηση στο Google Scholar](https://scholar.google.gr/scholar?hl=en&as_sdt=0%2C5&q=cifar+100+cnn&oq=cifa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LZIFj-AmlPv",
        "colab_type": "text"
      },
      "source": [
        "### Μεταφορά μάθησης\n",
        "\n",
        "Εναλλακτικά, μπορείτε να χρησιμοποιήσετ τη [μεταφορά μάθησης του tf2](https://www.tensorflow.org/tutorials/images/transfer_learning). Σε αντίθεση με τα μοντέλα \"from scratch\" η μεταφορά μάθησης μας επιστρέφει έτοιμα μοντέλα με προκαθορισμένη αρχιτεκτονική στην οποία μπορούμε γενικά μόνο να προσθέσουμε επίπεδα, τα οποία συνήθως περιορίζοντα σε πλήρως διασυνδεδεμένα επίπεδα που εξειδικεύονται στο συγκεκριμένο task ταξινόμησης που έχουμε να επιτελέσουμε. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrCxOjJ7ush3",
        "colab_type": "text"
      },
      "source": [
        "#### Εκπαίδευση βαρών\n",
        "\n",
        "Ταυτόχρονα με την αρχιτεκτονική, στη μεταφορά μάθησης εισάγουμε και τη γνώση που έχει αποκτήσει το μοντέλο, δηλαδή τις τιμές των βαρών του όπως έχουν προκύψει μετά από εκπαίδευση συνήθως στο (τεράστιο) ImageNet. Οταν εισάγουμε ένα μοντέλο με μεταφορά μάθησης έχουμε τρεις επιλογές για την εκπαίδευση:\n",
        "- να παγώσουμε τη συνελικτική βάση και να εκπαιδεύσουμε την κεφαλή ταξινόμησης (classification head). Αυτό αντιστοιχεί στο να χρησιμοποιήσουμε τη συνελικτική βάση για εξαγωγή χαρακτηριστικών (feature extraction), σημαία trainable = False.\n",
        "- να συνεχίσουμε να εκπαιδεύουμε όλα τα επίπεδα του δικτύου, σημαία trainable = True.\n",
        "- να εκπαιδευτεί μόνο ένα ποσοστό των επιπέδων, εβρισκόμενο προς την έξοδο του δικτύου. Οι σημαίες trainable εδώ θα πρέπει να οριστούν ανά επίπεδο.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WFvmWr9xEUz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### Διαθέσιμα μοντέλα για μεταφορά μάθησης στο tf2\n",
        "\n",
        "1. tf.keras.applications. Ο πιο απλός τρόπος για να κάνουμε μεταφορά μάθησης στο tf2 είναι μέσω του [tf.keras.applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications) που παρέχει προεκπαιδευμένα μοντέλα από το Keras και συγκεκριμένα τα δίκτυα: DenseNet, Inception-ResNet V2, Inception V3, MobileNet v1, MobileNet v2, NASNet-A, ResNet, ResNet v2, VGG16, VGG19 και Xception V1. Η εισαγωγή των μοντέλων γίνεται παρόμοια με αυτή που δείξαμε παραπάνω για το VGG16.\n",
        "\n",
        "2. TensorFlow Hub. Μπορείτε επίσης να χρησιμοποιήσετε μοντέλα τα οποία είναι διαθέσιμα στο αποθετήριο [TensoFlow Hub](https://tfhub.dev/s?fine-tunable=yes&module-type=image-augmentation,image-classification,image-feature-vector,image-generator,image-object-detection,image-others,image-style-transfer,image-rnn-agent&tf-version=tf2) το οποίο περιλαμβάνει πάνω από 100 προεκπαιδευμένα μοντέλα.\n",
        "\n",
        "3. Αποθηκευμένα μοντέλα απο τρίτες πηγές. Μπορείτε επίσης να κάνετε μεταφορά μάθησης από τρίτες πηγές, είτε του συνόλου του νευρωνικού, αρχιτεκτονικής και βαρών, είτε μόνο της αρχιτεκτονικής ή των βαρών. Το μοντέλο θα πρέπει να έχει αποθηκευθεί σε ένα από τα δύο φορμάτ, Keras HDF5 format (.h5 ή .keras) ή ως στο SavedModel format που αναφέραμε στην εισαγωγή. Τα βάρη μπορούν να εισαχθούν και μόνα τους ως Checkpoints. Για περισσότερα, διαβάστε σχετικά τα λήμματα [\"Save and load models\"](https://www.tensorflow.org/tutorials/keras/save_and_load), [\"Save and serialize\"](https://www.tensorflow.org/guide/keras/save_and_serialize), [\"Using the SavedModel format\"](https://www.tensorflow.org/guide/saved_model) και δείτε για παράδειγμα πως μπορούμε να κάνουμε μεταφορά μάθησης από τα state-of-the-art EfficientNets ([1](https://www.dlology.com/blog/transfer-learning-with-efficientnet/), [2](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnethttps://)).\n",
        "\n",
        "Σημειώστε ότι πολλά μοντέλα απαιτούν μεγαλύτερες διαστάσεις στην είσοδο από αυτές του CIFAR-100 και κατά συνέπεια τα δεδομένα πρέπει να [μετασχηματιστούν](https://www.tensorflow.org/api_docs/python/tf/image/resize). Προσέξτε ωστόσο τις απαιτήσεις σε μνήμη όταν αυτοί οι μετασχηματισμοί γίνονται απευθείας σε μεταβλητές (βλ. πιο κάτω \"Διαχείριση μνήμης\"). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRI_3XhBQ7sb",
        "colab_type": "text"
      },
      "source": [
        "## Παρατηρήσεις ως προς τη βελτιστοποίηση"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtVx8MsZRQrn",
        "colab_type": "text"
      },
      "source": [
        "### Διαχείριση μνήμης (TFRecord)\n",
        "\n",
        "Η φόρτωση δεδομένων με τον τρόπο που το κάναμε παραπάνω στο απλό παράδειγμα υλοποίησης είναι πολύ βολική αλλά δεν είναι καθόλου αποτελεσματική ως προς τη διαχείριση της μνήμης. Συγκεκριμένα, με τον τρόπο αυτό, τα δεδομένα αποθηκεύονται απευθείας σε μεταβλητές, οι οποίες όλες μαζί καταλαμβάνουν τη RAM της CPU ή της GPU, κάτι που κάνει αδύνατη τη διαχείριση μεγάλων datasets ή τον μεταχηματισμό των δεδομένων όπως όταν κάνουμε αύξηση δεδομένων (data augmentation).\n",
        "\n",
        "Για να παρακαμφθεί αυτό το πρόβλημα, υπάρχει η δυνατότητα της σειριοποίησης των δεδομένων (serialization) και της αποθήκευσής τους σε αρχεία μεσαίου μεγέθους (κάποιων MB) τα οποία μπορούνα να αναγνωστούν γραμμικά. Το φορμάτ TFRecord είναι ένα φορμάτ που επιτρέπει την αποθήκευση σειράς δυαδικών εγγραφών. Διαβάστε τα σχετικά λήμματα [TFRecord and tf.Example](https://www.tensorflow.org/tutorials/load_data/tfrecord) και [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data). \n",
        "\n",
        "Σημειώστε ότι με τη μέθοδο αυτή θα πρέπει να γίνει import η `tensorflow_datasets` και να χρησιμοποιήσουμε την `tfds.load` ώστε να αποθηκευθεί το σύνολο δεδομένων σε αρχεία tfrecord στο δίσκο (δείτε [εδώ](https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/overview.ipynb) ένα παράδειγμα). Φυσικά μπορούμε να μετατρέψουμε και τα πρωτογενή δεδομένα (raw data) του dataset όπως αρχεία jpg σε φορματ tfrecord όπως [εδώ](https://towardsdatascience.com/working-with-tfrecords-and-tf-train-example-36d111b3ff4d).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yypACH_oZx_i",
        "colab_type": "text"
      },
      "source": [
        "### Υπερεκπαίδευση\n",
        "\n",
        "Μπορείτε να πειραματιστείτε ως προς τον έλεγχο της υπερεκπαίδευσης (overfitting) με διάφορους τρόπους. Μεταξύ αυτών μπορούμε να αναφέρουμε τους εξής:\n",
        "- Πρόωρος τερματισμός (early stopping). Μια μέθοδος που τερματίζει την εκπαίδευση αν δεν υπάρχει βελτίωση ως προς τη μετρική απόδοσης που παρακολουθούμε. [tf.keras.callbacks.EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStoppinghttps://)\n",
        "- Dropout. Μια άλλη τεχνική για τη μείωση της υπερεκπαίδευσης είναι το Dropout. Είναι ένα είδος ομαλοποίησης (regularization) που επιβάλλει στα βάρη του δικτύου να παίρνουν μόνο μικρές τιμές. Εάν εφαρμόσουε dropout σε ένα επίπεδο του δικτύου, τότε ένα ποσοστό των βαρών του γίνεται τυχαία μηδενικό κατά την εκπαίδευση. [Dropout](https://www.tensorflow.org/tutorials/images/classification#dropout)\n",
        "- Επαύξηση δεδομένων. Η υπερεκπαίδευση συνήθως συμβαίνει όταν έχουμε λίγα ή/και πολύ όμοια δεδομένα εκπαίδευσης. Ένας τρόπος να διορθωθεί αυτό το πρόβλημα είναι να αυξήσουμε τα δεδομένα (data augmentation). Το data augmentation δημιουργεί νέα δεδομένα εκπαίδευσης με βάση τα υπάρχοντα εφαρμόζοντας τυχαίους μετασχηματισμούς ώστε να προκύπτουν αληθοφανείς εικόνες. [Data augmentation](https://www.tensorflow.org/tutorials/images/classification#data_augmentation), [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#class_imagedatagenerator)\n",
        "\n",
        "Βλέπε επίσης [Image classification](https://www.tensorflow.org/tutorials/images/classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBLBjFFFmsUP",
        "colab_type": "text"
      },
      "source": [
        "### Χρόνος εκπαίδευσης\n",
        "\n",
        "Το TensorFlow 2 προσφέρει νέους ή βελτιώνει διάφορους μηχανισμούς βελτιστοποίησης της εκπαίδευσης. Μεταξύ αυτών έχουμε τους εξής:\n",
        "- Data prefetching (το χρησιμοποιήσαμε παραπάνω)\n",
        "- Data reading parallelization \n",
        "- Map transformation parallelization\n",
        "- Caching\n",
        "- Reducing memory footprint\n",
        "\n",
        "Συμβουλευτείτε για τα παραπάνω το [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3ddu1ECoCGQ",
        "colab_type": "text"
      },
      "source": [
        "### Εργαλεία υψηλού επιπέδου\n",
        "\n",
        "Μεταξύ των εργαλείων βελτιστοποίησης υψηλού επιπέδου (high-level) του TensorFlow μπορούμε να αναφέρουμε τα ακόλουθα:\n",
        "\n",
        "- [TensorBoard](https://www.tensorflow.org/tensorboard/get_started) και [What-If Tool](https://www.tensorflow.org/tensorboard/what_if_tool) Επικουρικό εργαλείο οπτικοποίησης για τον πειραματισμό στη Μηχανική Μάθηση\n",
        "- [tf-explain](https://tf-explain.readthedocs.io/en/latest/) Προσφέρει μεθόδους επεξηγισιμότητας για το tf2\n",
        "- [Keras Tuner](https://github.com/keras-team/keras-tuner) Βελτιστοποίηση υπερπαραμέτρων του Keras στο TensorFlow 2.0\n",
        "- [AutoAugment](https://github.com/tensorflow/models/tree/master/research/autoaugment) Εκμάθηση της πολιτικης επαύξησης από τα δεδομένα"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glBWZ6_ZvGlt",
        "colab_type": "text"
      },
      "source": [
        "# Easter eggs για το τέλος του μαθήματος Νευρωνικών 2019-2020\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNHFNS981Qh0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## What's next for Deep Learning\n",
        "\n",
        "The Godfathers of AI and 2018 ACM Turing Award winners Geoffrey Hinton, Yann LeCun, and Yoshua Bengio shared a stage in New York on Sunday night at an event organized by the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020). The trio of researchers have made deep neural networks a critical component of computing, and in individual talks and a panel discussion they discussed their views on current challenges facing deep learning and where it should be heading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECLw-wy_wGvm",
        "colab_type": "code",
        "outputId": "05eee951-8a55-47d1-c6db-1f2e873db014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame(src='https://www.youtube.com/embed/UX8OubxsY8w', width=640, height=480)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"640\"\n",
              "            height=\"480\"\n",
              "            src=\"https://www.youtube.com/embed/UX8OubxsY8w\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f3fc27d83c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwhiplJkzR1W",
        "colab_type": "text"
      },
      "source": [
        "## Αντίλογος: η κριτική του Schmidhuber για τους LeCun & Bengio & Hinton\n",
        "\n",
        "(Ο Schmidhuber και ο Hochreiter [εισήγαγαν τα LSTM το 1997](https://www.bioinf.jku.at/publications/older/2604.pdf))\n",
        "\n",
        "*Machine learning is the science of credit assignment. The machine learning community itself profits from proper credit assignment to its members. The inventor of an important method should get credit for inventing it. She may not always be the one who popularizes it. Then the popularizer should get credit for popularizing it (but not for inventing it). Relatively young research areas such as machine learning should adopt the honor code of mature fields such as mathematics: if you have a new theorem, but use a proof technique similar to somebody else's, you must make this very clear. If you \"re-invent\" something that was already known, and only later become aware of this, you must at least make it clear later.*\n",
        "\n",
        "*As a case in point, let me now comment on a recent article in [Nature (2015) about \"deep learning\"](http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html) in artificial neural networks (NNs), by LeCun & Bengio & Hinton (LBH for short), three CIFAR-funded collaborators who call themselves the \"deep learning conspiracy\" (e.g., LeCun, 2015). They heavily cite each other. Unfortunately, however, they fail to credit the pioneers of the field, which originated half a century ago. All references below are taken from the recent [deep learning overview](http://www.idsia.ch/~juergen/deep-learning-overview.html) (Schmidhuber, 2015), except for a few papers listed beneath this critique focusing on nine items.*\n",
        "\n",
        "[Read more...](http://people.idsia.ch/~juergen/deep-learning-conspiracy.html)"
      ]
    }
  ]
}